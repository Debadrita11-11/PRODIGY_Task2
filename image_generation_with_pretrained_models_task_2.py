# -*- coding: utf-8 -*-
"""Image generation with pretrained models_task 2

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1JSkaNzQ6f6JCi5HmWdOXrYaHDrf1rEiQ
"""

!nvidia-smi

from google.colab import drive
drive.mount('/content/drive')

import os

directory_path = '/content/drive/MyDrive/AAAI'#@param {type:"string"}
folder_name = "images"  #@param {type:"string"}
directory_path_image = f'{directory_path}/{folder_name}'

!pip install diffusers==0.12.1 transformers==4.28.1 ftfy accelerate

from PIL import Image as PILImage
import os
import torch
from transformers import BlipProcessor, BlipForConditionalGeneration, CLIPTextModel, CLIPVisionModel, CLIPTokenizer
from diffusers import StableDiffusionPipeline
from IPython.display import Image, display

def generate_image(prompt, num_images, save_dir, compression_quality):
    device = "cuda"
    model_id = "CompVis/stable-diffusion-v1-4"

    # Create the directory if it doesn't exist
    os.makedirs(save_dir, exist_ok=True)

    # Generate the pipeline
    pipe = StableDiffusionPipeline.from_pretrained(model_id, revision="fp16", torch_dtype=torch.float16)
    pipe = pipe.to(device)

    for i in range(num_images):
        # Execute the pipeline
        generator = torch.Generator().manual_seed(60 + i)  # Change seed for each image
        with torch.autocast("cuda"):
            image = pipe(prompt, guidance_scale=7.5, generator=generator).images[0]

        # Save the image with a unique filename in the specified directory
        filename = os.path.join(save_dir, f"{prompt[:10]}_{i + 51}.jpg")
        image.save(filename, quality=compression_quality, optimize=True)

        # Print the size of the image file
        file_size = os.path.getsize(filename)
        print(f"Image {i + 1}: {filename}, Size: {file_size} bytes")
        display(Image(filename=filename))

# Parameters
prompt = "power outlets" #@param {type:"string"}
num_images = 50 #@param {type:"integer"}
save_dir = directory_path_image
compression_quality = 10 #@param {type:"integer"}
# Generate and save images
generate_image(prompt, num_images, save_dir, compression_quality)

!pip install OpenAI

import datetime
import time
import requests
import os

from PIL import Image
from io import BytesIO
from openai import OpenAI

# Parameters
api_key = "enter your api key" #@param {type:"string"}
prompt = "few white german power outlets which It is circular and has two outlets on the left and right and a ground on the top and bottom" #@param {type:"string"}
num_images = 60 #@param {type:"integer"}
client = OpenAI(api_key= api_key )


for j in range(0, num_images, 5):
    response = client.images.generate(
        model="dall-e-2",
        prompt=prompt,
        size="256x256",
        quality="standard",
        n=min(5, num_images - j)
    )

    for i, image_data in enumerate(response.data):
        image_url = image_data.url
        timestamp = datetime.datetime.now().strftime("%Y%m%d%H%M%S")
        file_name = f"image{j+i+1}{timestamp}.jpg"
        file_path = directory_path_image

        response = requests.get(image_url)
        image = Image.open(BytesIO(response.content))

        quality = 20
        image.save(file_path, 'JPEG', quality=quality)

        print(f"Saved image size: {os.path.getsize(file_path)} bytes")

    if j + 5 < num_images:
        time.sleep(60)

!pip install -q \
autodistill \
autodistill-grounded-sam \
autodistill-yolov8 \
roboflow \
supervision==0.9.0

import supervision as sv

image_paths = sv.list_files_with_extensions(
    directory= directory_path_image,
    extensions=["jpg"])

print(image_paths)
print('image count:', len(image_paths))

import cv2

SAMPLE_SIZE = 16
SAMPLE_GRID_SIZE = (4, 4)
SAMPLE_PLOT_SIZE = (16, 16)

titles = [
    image_path.stem
    for image_path
    in image_paths[:SAMPLE_SIZE]]
images = [
    cv2.imread(str(image_path))
    for image_path
    in image_paths[:SAMPLE_SIZE]]

sv.plot_images_grid(images=images, titles=titles, grid_size=SAMPLE_GRID_SIZE, size=SAMPLE_PLOT_SIZE)

from autodistill.detection import CaptionOntology

os.chdir(directory_path)
print("Current Directory:", os.getcwd())

ontology=CaptionOntology({
    "power outlet": "power outlet",
})

IMAGE_DIR_PATH = f'{directory_path}/images'
DATASET_DIR_PATH = f'{directory_path}/dataset'

from autodistill_grounded_sam import GroundedSAM

base_model = GroundedSAM(ontology=ontology)
dataset = base_model.label(
    input_folder=IMAGE_DIR_PATH,
    output_folder=DATASET_DIR_PATH,
    record_confidence= True)

IMAGES_DIRECTORY_PATH = f'{directory_path}/dataset/train/images'
ANNOTATIONS_DIRECTORY_PATH = f'{directory_path}/dataset/train/labels'
DATA_YAML_PATH = f'{directory_path}/dataset/data.yaml'

import supervision as sv

dataset = sv.DetectionDataset.from_yolo(
    images_directory_path=IMAGES_DIRECTORY_PATH,
    annotations_directory_path=ANNOTATIONS_DIRECTORY_PATH,
    data_yaml_path=DATA_YAML_PATH)

len(dataset)

import supervision as sv

image_names = list(dataset.images.keys())[:SAMPLE_SIZE]

mask_annotator = sv.MaskAnnotator()
box_annotator = sv.BoxAnnotator()

images = []
for image_name in image_names:
    image = dataset.images[image_name]
    annotations = dataset.annotations[image_name]
    labels = [
        dataset.classes[class_id]
        for class_id
        in annotations.class_id]
    annotates_image = mask_annotator.annotate(
        scene=image.copy(),
        detections=annotations)
    annotates_image = box_annotator.annotate(
        scene=annotates_image,
        detections=annotations,
        labels=labels)
    images.append(annotates_image)

sv.plot_images_grid(
    images=images,
    titles=image_names,
    grid_size=SAMPLE_GRID_SIZE,
    size=SAMPLE_PLOT_SIZE)

from autodistill_yolov8 import YOLOv8
import os

os.chdir(directory_path)
print("Current Directory:", os.getcwd())

target_model = YOLOv8("yolov8n.pt")
target_model.train(DATA_YAML_PATH, epochs=30)

from IPython.display import Image

file_paths = [
    f'{directory_path}/runs/detect/train/train_batch0.jpg',
    f'{directory_path}/runs/detect/train/train_batch1.jpg',
    f'{directory_path}/runs/detect/train/train_batch2.jpg'
]

for file_path in file_paths:
    display(Image(filename=file_path, width=600))

Image(filename=f'{directory_path}/runs/detect/train/results.png', width=600)

Image(filename=f'{directory_path}/runs/detect/train/confusion_matrix.png', width=600)

Image(filename=f'{directory_path}/runs/detect/train/val_batch0_labels.jpg', width=600)

Image(filename=f'{directory_path}/runs/detect/train/val_batch0_pred.jpg', width=600)

import locale
locale.getpreferredencoding = lambda: "UTF-8"

!pip install roboflow

import os

os.chdir(directory_path)
print("Current Directory:", os.getcwd())

from roboflow import Roboflow
rf = Roboflow(api_key="u01WhJv4xeBP6ceylN5o")
project = rf.workspace("yolov5-power-socket-detection").project("power-socket-detection-jbgd5")
dataset = project.version(1).download("yolov8")

# from roboflow import Roboflow
# rf = Roboflow(api_key="u01WhJv4xeBP6ceylN5o")
# project = rf.workspace("luka-trikha").project("outlets-3wtws")
# dataset = project.version(3).download("yolov8")

import shutil
import os

test_directry = "Power-Socket-Detection-1" #@param {type:"string"}

source = os.path.join(directory_path, f'{test_directry}/data.yaml')
destination = os.path.join(directory_path, "data.yaml")

source2 = os.path.join(directory_path, f'{test_directry}/test')
destination2 = os.path.join(directory_path, "test")

shutil.move(source, destination)
shutil.move(source2, destination2)

import os

os.chdir(directory_path)
print("Current Directory:", os.getcwd())

!yolo task=detect mode=val split=test model={directory_path}/runs/detect/train/weights/best.pt data={directory_path}/data.yaml

from IPython.display import Image

Image(filename=f'{directory_path}/runs/detect/val/confusion_matrix.png', width=600)

file_paths = [
    f'{directory_path}/runs/detect/val/val_batch0_labels.jpg',
    f'{directory_path}/runs/detect/val/val_batch1_labels.jpg',
    f'{directory_path}/runs/detect/val/val_batch2_labels.jpg'
]

for file_path in file_paths:
    display(Image(filename=file_path, width=600))

file_paths = [
    f'{directory_path}/runs/detect/val/val_batch0_pred.jpg',
    f'{directory_path}/runs/detect/val/val_batch1_pred.jpg',
    f'{directory_path}/runs/detect/val/val_batch2_pred.jpg'
]

for file_path in file_paths:
    display(Image(filename=file_path, width=600))